{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéß QualiVault: Prepare Audio\n",
    "**Goal:** Convert raw audio files to 16-bit 16kHz FLAC, analyze channel separation, and count speakers.\n",
    "\n",
    "1. Reads `processing_recipe.yaml`.\n",
    "2. Converts/Merges audio files using `ffmpeg`.\n",
    "3. Saves them to the configured `flac_output_folder` (outside the git repo).\n",
    "4. **Analyzes Stereo Separation:** Checks if Left/Right channels are distinct.\n",
    "5. **Counts Speakers:** Uses Pyannote AI to estimate speakers per channel.\n",
    "6. Updates `processing_recipe.yaml` with the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from pyannote.audio import Pipeline\n",
    "from qualivault.audio import prepare_audio, analyze_channel_separation\n",
    "\n",
    "# 1. Load Configuration\n",
    "project_root = Path(\"..\").resolve()\n",
    "config_path = project_root / \"config.yml\"\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Suppress warnings if configured\n",
    "if config.get(\"suppress_warnings\", True):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 2. Setup Output Folder\n",
    "# Resolve path relative to project root\n",
    "output_dir = (project_root / config['paths']['flac_output_folder']).resolve()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ FLAC Output Directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Recipe\n",
    "recipe_path = project_root / \"processing_recipe.yaml\"\n",
    "if not recipe_path.exists():\n",
    "    print(\"‚ùå Recipe not found! Please run '00_Setup_and_Scan.ipynb' first.\")\n",
    "    recipe = []\n",
    "else:\n",
    "    with open(recipe_path) as f:\n",
    "        recipe = yaml.safe_load(f)\n",
    "    print(f\"‚úÖ Loaded recipe with {len(recipe)} interviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize AI Pipeline (Pyannote)\n",
    "hf_token = config.get('hf_token')\n",
    "pipeline = None\n",
    "\n",
    "if hf_token:\n",
    "    try:\n",
    "        print(\"‚è≥ Initializing Pyannote Pipeline...\")\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", \n",
    "                                            use_auth_token=hf_token)\n",
    "        \n",
    "        # Move to GPU/MPS if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        pipeline.to(device)\n",
    "        print(f\"‚úÖ Pyannote initialized on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not initialize Pyannote: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No HF_TOKEN found in config. Skipping speaker counting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Process Audio & Analyze\n",
    "processed_paths = {}\n",
    "for item in recipe:\n",
    "    i_id = item['id']\n",
    "    input_files = item['files']\n",
    "    output_name = item['output_name']\n",
    "    output_path = output_dir / output_name\n",
    "    \n",
    "    print(f\"\\nüéß Processing Interview: {i_id}\")\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"  ‚úÖ File already exists: {output_path.name}\")\n",
    "        processed_paths[i_id] = output_path\n",
    "    else:\n",
    "        try:\n",
    "            prepare_audio(input_files, output_path)\n",
    "            print(f\"  ‚úÖ Converted to FLAC: {output_path.name}\")\n",
    "            processed_paths[i_id] = output_path\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Run Analysis\n",
    "    if output_path.exists():\n",
    "        analysis_stats = analyze_channel_separation(output_path, pipeline)\n",
    "        # Update recipe item with stats\n",
    "        item.update(analysis_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save Updated Recipe\n",
    "with open(recipe_path, 'w') as f:\n",
    "    yaml.dump(recipe, f, sort_keys=False)\n",
    "print(f\"\\nüíæ Updated recipe saved to {recipe_path}\")\n",
    "print(\"   (You can now manually edit speaker counts in the YAML if needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Quality Check\n",
    "Loading all audio files at once can crash the kernel. Use the cell below to play specific files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an interview ID to play (change the index or ID string)\n",
    "if processed_paths:\n",
    "    # Example: Play the first one\n",
    "    target_id = list(processed_paths.keys())[0]\n",
    "    target_path = processed_paths[target_id]\n",
    "    \n",
    "    print(f\"‚ñ∂Ô∏è Playing: {target_id} ({target_path.name})\")\n",
    "    display(ipd.Audio(filename=target_path))\n",
    "else:\n",
    "    print(\"No files processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}