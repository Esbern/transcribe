{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b3cfa8",
   "metadata": {},
   "source": [
    "# üîç QualiVault: Validate Transcripts\n",
    "**Goal:** Use Ollama (local LLM) to detect transcription errors and hallucinations.\n",
    "\n",
    "1. Loads transcripts from CSV files.\n",
    "2. Samples segments and sends them to Ollama for validation.\n",
    "3. Flags potential errors: hallucinations, misheard words, artifacts.\n",
    "4. Generates validation report with suggestions.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Ollama must be installed and running (`ollama serve`)\n",
    "- Install a model: `ollama pull llama3.1` or `ollama pull jobautomation/OpenEuroLLM-Danish:latest`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "‚ùå Project not found: c:\\dev\\qualvalt\\projects\\YOUR_PROJECT_NAME\n   Available projects in c:\\dev\\qualvalt\\projects:",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Verify project exists\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m project_root.exists():\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå Project not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   Available projects in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworkspace_root\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprojects\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m config_path = project_root / \u001b[33m'\u001b[39m\u001b[33mconfig.yml\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config_path.exists():\n",
      "\u001b[31mFileNotFoundError\u001b[39m: ‚ùå Project not found: c:\\dev\\qualvalt\\projects\\YOUR_PROJECT_NAME\n   Available projects in c:\\dev\\qualvalt\\projects:"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from qualivault.validation import OllamaValidator, validate_recipe_transcripts\n",
    "from qualivault import find_workspace_root\n",
    "\n",
    "# ============================================\n",
    "# PROJECT CONFIGURATION\n",
    "# ============================================\n",
    "# Specify your project folder name here:\n",
    "PROJECT_NAME = 'YOUR_PROJECT_NAME'  # <-- Change this to your project folder name\n",
    "\n",
    "# Auto-detect workspace root and project path\n",
    "workspace_root = find_workspace_root(Path.cwd())\n",
    "project_root = workspace_root / 'projects' / PROJECT_NAME\n",
    "\n",
    "# Verify project exists\n",
    "if not project_root.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"‚ùå Project not found: {project_root}\\n   Available projects in {workspace_root / 'projects'}:\"\n",
    "    )\n",
    "\n",
    "config_path = project_root / 'config.yml'\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Config not found: {config_path}\")\n",
    "\n",
    "print(f\"üéØ Working on project: {PROJECT_NAME}\")\n",
    "print(f\"üìÅ Project root:       {project_root}\")\n",
    "print(f\"‚öôÔ∏è  Config file:        {config_path}\")\n",
    "print()\n",
    "\n",
    "# 1. Load Configuration\n",
    "with open(config_path, encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "recipe_path = project_root / \"processing_recipe.yaml\"\n",
    "transcripts_dir = (project_root / config['paths']['output_base_folder']).resolve()\n",
    "\n",
    "print(f\"üìÇ Transcripts: {transcripts_dir}\")\n",
    "print(f\"üìã Recipe: {recipe_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121eabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check Ollama Installation and Available Models\n",
    "import requests\n",
    "import json\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "\n",
    "def check_ollama():\n",
    "    \"\"\"Test if Ollama is running and list available models.\"\"\"\n",
    "    print(\"üîç Checking Ollama installation...\\n\")\n",
    "    \n",
    "    # Test connection\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Ollama is running!\")\n",
    "            \n",
    "            # List available models\n",
    "            data = response.json()\n",
    "            models = data.get('models', [])\n",
    "            \n",
    "            if models:\n",
    "                print(f\"\\nüì¶ Available models ({len(models)}):\\n\")\n",
    "                \n",
    "                for model in models:\n",
    "                    name = model.get('name', 'Unknown')\n",
    "                    size_gb = model.get('size', 0) / (1024**3)\n",
    "                    \n",
    "                    # Highlight Danish model\n",
    "                    if 'danish' in name.lower() or 'openeuro' in name.lower():\n",
    "                        print(f\"   üá©üá∞ {name} ({size_gb:.1f} GB) ‚Üê Recommended for Danish\")\n",
    "                    elif 'llama3' in name.lower():\n",
    "                        print(f\"   ü¶ô {name} ({size_gb:.1f} GB) ‚Üê Good general model\")\n",
    "                    else:\n",
    "                        print(f\"   ‚Ä¢ {name} ({size_gb:.1f} GB)\")\n",
    "                \n",
    "                print(\"\\nüí° Recommendation:\")\n",
    "                danish_models = [m for m in models if 'danish' in m.get('name', '').lower() or 'openeuro' in m.get('name', '').lower()]\n",
    "                \n",
    "                if danish_models:\n",
    "                    print(f\"   Use: '{danish_models[0]['name']}' (Danish-optimized)\")\n",
    "                elif any('llama3' in m.get('name', '').lower() for m in models):\n",
    "                    llama3 = [m for m in models if 'llama3' in m.get('name', '').lower()][0]\n",
    "                    print(f\"   Use: '{llama3['name']}' (general purpose)\")\n",
    "                else:\n",
    "                    print(f\"   Use: '{models[0]['name']}'\")\n",
    "                \n",
    "                return True, models\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Ollama is running but no models are installed!\")\n",
    "                print(\"\\nüì• Install a model:\")\n",
    "                print(\"   For Danish: ollama pull jobautomation/OpenEuroLLM-Danish:latest\")\n",
    "                print(\"   General:    ollama pull llama3.1\")\n",
    "                return False, []\n",
    "        else:\n",
    "            print(f\"‚ùå Ollama responded with error: {response.status_code}\")\n",
    "            return False, []\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"‚ùå Cannot connect to Ollama!\")\n",
    "        print(\"\\nüîß To fix:\")\n",
    "        print(\"   1. Install Ollama: https://ollama.ai\")\n",
    "        print(\"   2. Start Ollama: ollama serve\")\n",
    "        print(\"   3. Pull a model: ollama pull llama3.1\")\n",
    "        return False, []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Ollama: {e}\")\n",
    "        return False, []\n",
    "\n",
    "# Run the check\n",
    "ollama_ok, available_models = check_ollama()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da901b57",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Adjust these settings to control validation:\n",
    "\n",
    "- **model**: Ollama model to use (`llama2`, `mistral`, `llama3`, etc.)\n",
    "- **sample_rate**: Fraction of segments to check (0.1 = 10%, 1.0 = 100%)\n",
    "- **language**: Expected language of transcripts\n",
    "- **ollama_url**: URL where Ollama is running (default: localhost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Settings\n",
    "# Auto-select the best available model from the list above\n",
    "if ollama_ok and available_models:\n",
    "    # Prefer Danish models, then llama3, then first available\n",
    "    danish_models = [m for m in available_models if 'danish' in m.get('name', '').lower() or 'openeuro' in m.get('name', '').lower()]\n",
    "    llama3_models = [m for m in available_models if 'llama3' in m.get('name', '').lower()]\n",
    "    \n",
    "    if danish_models:\n",
    "        MODEL = danish_models[0]['name']\n",
    "    elif llama3_models:\n",
    "        MODEL = llama3_models[0]['name']\n",
    "    else:\n",
    "        MODEL = available_models[0]['name']\n",
    "else:\n",
    "    MODEL = \"llama3.1\"  # Fallback if check didn't run\n",
    "\n",
    "SAMPLE_RATE = 0.1           # Check 10% of segments (faster, set to 1.0 for 100%)\n",
    "LANGUAGE = \"Danish\"         # Expected language\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "TIMEOUT = 120               # Timeout in seconds (increase for large models)\n",
    "\n",
    "VALIDATION_PARAMS = {\n",
    "    \"sample_rate\": SAMPLE_RATE,\n",
    "    \"min_text_length\": 8,\n",
    "    \"max_segments\": None,\n",
    "    \"timeout\": TIMEOUT,\n",
    "    \"ollama_options\": {\"temperature\": 0.3, \"top_p\": 0.9}\n",
    "}\n",
    "\n",
    "print(f\"ü§ñ Model: {MODEL}\")\n",
    "print(f\"üìä Sample Rate: {SAMPLE_RATE * 100}%\")\n",
    "print(f\"üåç Language: {LANGUAGE}\")\n",
    "print(f\"‚è±Ô∏è  Timeout: {TIMEOUT}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d5f84",
   "metadata": {},
   "source": [
    "## Test Ollama Connection\n",
    "\n",
    "Make sure Ollama is running before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = OllamaValidator(model=MODEL, ollama_url=OLLAMA_URL)\n",
    "\n",
    "# Quick test\n",
    "test_response = validator._query_ollama(\"Say 'Hello' in one word.\")\n",
    "if test_response:\n",
    "    print(f\"‚úÖ Ollama is responding: '{test_response.strip()[:50]}'\")\n",
    "else:\n",
    "    print(\"‚ùå Ollama is not responding. Make sure it's running: `ollama serve`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c8afc0",
   "metadata": {},
   "source": [
    "## Validate All Transcripts\n",
    "\n",
    "This will:\n",
    "1. Load all transcribed interviews from the recipe\n",
    "2. Sample segments from each CSV\n",
    "3. Check each segment with Ollama for errors\n",
    "4. Save individual validation report for each interview\n",
    "5. Create summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a42e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation on all transcripts - Save individual report for each interview\n",
    "from datetime import datetime\n",
    "\n",
    "from qualivault import validate_transcripts_to_individual_reports\n",
    "\n",
    "# RESUME OPTION: Set to True to re-validate all files (overwrites existing reports)\n",
    "FORCE_REVALIDATE = False  # Set to True to start fresh, False to resume from last position\n",
    "\n",
    "print(f\"üîç Starting validation at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"   Model: {MODEL}\")\n",
    "print(f\"   Sample Rate: {VALIDATION_PARAMS['sample_rate'] * 100}%\")\n",
    "print(f\"   Max Interviews: {VALIDATION_PARAMS.get('max_interviews') or 'All'}\")\n",
    "print(f\"   Resume Mode: {'OFF (re-validate all)' if FORCE_REVALIDATE else 'ON (skip existing)'}\")\n",
    "print(f\"   Scanning: {transcripts_dir}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "reports_dir = project_root / \"validation_reports\"\n",
    "\n",
    "all_results = validate_transcripts_to_individual_reports(\n",
    "    transcripts_dir=transcripts_dir,\n",
    "    reports_dir=reports_dir,\n",
    "    model=MODEL,\n",
    "    ollama_url=OLLAMA_URL,\n",
    "    language=LANGUAGE,\n",
    "    validation_params=VALIDATION_PARAMS,\n",
    "    resume=(not FORCE_REVALIDATE),\n",
    "    max_files=VALIDATION_PARAMS.get(\"max_interviews\"),\n",
    ")\n",
    "\n",
    "# Backwards-compat variable name for older cells\n",
    "results = all_results\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"‚úÖ Validation complete at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"   Total with reports: {len(all_results)}\")\n",
    "print(f\"   Reports saved to: {reports_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7eb72",
   "metadata": {},
   "source": [
    "## Review Validation Reports\n",
    "\n",
    "Inspect flagged segments and issues across all transcripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics - Load all individual reports and aggregate\n",
    "from qualivault import (\n",
    "    aggregate_validation_reports,\n",
    "    load_validation_reports,\n",
    ")\n",
    "\n",
    "reports_dir = project_root / \"validation_reports\"\n",
    "all_results = load_validation_reports(reports_dir)\n",
    "\n",
    "print(f\"üìÇ Loading {len(all_results)} validation reports\\n\")\n",
    "\n",
    "df, totals = aggregate_validation_reports(reports_dir=reports_dir, all_results=all_results)\n",
    "\n",
    "total_checked = totals[\"total_segments_checked\"]\n",
    "total_flagged = totals[\"total_segments_flagged\"]\n",
    "\n",
    "print(f\"üìä VALIDATION SUMMARY\")\n",
    "print(f\"=\" * 70)\n",
    "print(f\"Files validated: {totals['files_validated']}\")\n",
    "print(f\"Total segments checked: {total_checked}\")\n",
    "print(f\"Total segments flagged: {total_flagged}\")\n",
    "if total_checked > 0:\n",
    "    print(f\"Flag rate: {(total_flagged / total_checked * 100):.1f}%\")\n",
    "print(f\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìÅ Per-File Results:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüíæ Summary saved to: {reports_dir / 'SUMMARY.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b1215",
   "metadata": {},
   "source": [
    "## Detailed Issue Review\n",
    "\n",
    "Examine specific flagged segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5243e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed issues for first transcript\n",
    "from qualivault import load_validation_reports\n",
    "\n",
    "try:\n",
    "    all_results\n",
    "except NameError:\n",
    "    all_results = load_validation_reports(project_root / \"validation_reports\")\n",
    "\n",
    "if all_results and all_results[0].get(\"flagged_segments\"):\n",
    "    report = all_results[0]\n",
    "    print(f\"\\nüîç Detailed issues for: {report.get('csv_file', 'unknown')}\\n\")\n",
    "\n",
    "    for seg in report[\"flagged_segments\"][:10]:  # Show first 10\n",
    "        print(f\"Segment {seg['segment_index']} ({seg['start']:.1f}s - {seg['end']:.1f}s)\")\n",
    "        print(f\"Speaker: {seg['speaker']}\")\n",
    "        print(f\"Text: {seg['text']}\")\n",
    "        print(f\"Issues: {', '.join(seg['issues'])}\")\n",
    "        print(f\"Confidence: {seg['confidence']:.2f}\")\n",
    "        if seg.get(\"suggestions\"):\n",
    "            print(f\"Suggestions: {seg['suggestions']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No issues found in first transcript.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dfb1d",
   "metadata": {},
   "source": [
    "## Export Validation Report\n",
    "\n",
    "Create master summary file with links to individual validation reports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Master Summary Report\n",
    "from qualivault import (\n",
    "    load_validation_reports,\n",
    "    write_master_validation_summary,\n",
    ")\n",
    "\n",
    "reports_dir = project_root / \"validation_reports\"\n",
    "\n",
    "try:\n",
    "    all_results\n",
    "except NameError:\n",
    "    all_results = load_validation_reports(reports_dir)\n",
    "\n",
    "summary_file = write_master_validation_summary(\n",
    "    reports_dir=reports_dir,\n",
    "    all_results=all_results,\n",
    "    model=MODEL,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    language=LANGUAGE,\n",
    ")\n",
    "\n",
    "print(f\"üìã Master Summary Report\")\n",
    "print(f\"=\" * 70)\n",
    "print(f\"üìÅ Location: {summary_file}\")\n",
    "print(f\"   ‚Ä¢ Master summary: {summary_file.name}\")\n",
    "print(f\"   ‚Ä¢ Individual reports: {len(list(reports_dir.glob('*_validation.json')))} files\")\n",
    "print(f\"   ‚Ä¢ Summary CSV: SUMMARY.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qualivault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
