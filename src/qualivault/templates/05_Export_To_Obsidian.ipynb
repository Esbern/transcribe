{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9747cc",
   "metadata": {},
   "source": [
    "# ðŸ—‚ï¸ Export Transcripts to Obsidian\n",
    "Convert CSV transcripts to Markdown notes with Media Extended timestamp links, embedded validation snippets, and a quantitative questionnaire.\n",
    "\n",
    "Workflow:\n",
    "1. Load transcripts (CSV) and optional validation_report.json.\n",
    "2. Create Obsidian-friendly Markdown with timestamp links to audio.\n",
    "3. Append a removable validation block (italic tag) after each transcript.\n",
    "4. Append the quantitative questionnaire at the end of each note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525832a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Transcripts:       D:\\legendary2\\transcribe\n",
      "ðŸ“š Obsidian Vault:    D:\\legendary2\\obsidian_vault\n",
      "ðŸŽ§ Audio subfolder:   \"compact_audio\"\n",
      "ðŸŽ§ Audio vault path:  D:\\legendary2\\obsidian_vault\\compact_audio\n",
      "   â†³ Exists: True\n",
      "   â†³ Files found: 88\n",
      "ðŸ“ Output MD files:   D:\\legendary2\\obsidian_vault\n",
      "âœ… Validation report: True\n"
     ]
    }
   ],
   "source": [
    "# 1) Paths and inputs\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "project_root = Path('..').resolve()\n",
    "config_path = project_root / 'config.yml'\n",
    "\n",
    "# Load project config (used for default transcript/audio paths)\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "paths_cfg = config.get('paths', {})\n",
    "\n",
    "# Directories\n",
    "TRANSCRIPTS_DIR = Path(paths_cfg.get('output_base_folder', project_root)).expanduser().resolve()\n",
    "\n",
    "# Obsidian vault setup\n",
    "obsidian_vault = Path(paths_cfg.get('obsidian_vault_folder', project_root)).expanduser().resolve()\n",
    "compact_audio_subfolder = paths_cfg.get('compact_audio_folder', 'compact_audio')\n",
    "\n",
    "# Build the full audio vault path\n",
    "AUDIO_VAULT_DIR = obsidian_vault / compact_audio_subfolder\n",
    "\n",
    "# Output markdown goes to obsidian vault root\n",
    "OUTPUT_DIR = obsidian_vault\n",
    "VALIDATION_REPORT_PATH = project_root / 'validation_report.json'\n",
    "\n",
    "print(f'ðŸ“‚ Transcripts:       {TRANSCRIPTS_DIR}')\n",
    "print(f'ðŸ“š Obsidian Vault:    {obsidian_vault}')\n",
    "print(f'ðŸŽ§ Audio subfolder:   \"{compact_audio_subfolder}\"')\n",
    "print(f'ðŸŽ§ Audio vault path:  {AUDIO_VAULT_DIR}')\n",
    "print(f'   â†³ Exists: {AUDIO_VAULT_DIR.exists()}')\n",
    "if AUDIO_VAULT_DIR.exists():\n",
    "    audio_count = len(list(AUDIO_VAULT_DIR.glob(\"*\")))\n",
    "    print(f'   â†³ Files found: {audio_count}')\n",
    "print(f'ðŸ“ Output MD files:   {OUTPUT_DIR}')\n",
    "print(f'âœ… Validation report: {VALIDATION_REPORT_PATH.exists()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e6b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Questionnaire + settings\n",
    "TARGET_SPEAKER = 'SPEAKER_00'  # bolded in output\n",
    "\n",
    "QUESTION_SECTIONS = {\n",
    "    'Section Q2: Demographics': [\n",
    "        'Q2_1_person_interviewed', 'Q2_2_birthyear', 'Q2_3_residents',\n",
    "        'Q2_4_year_aqcuisition', 'Q2_5_income_outside_farm'\n",
    "    ],\n",
    "    'Section Q3: Farm Structure': [\n",
    "        'Q3_1_farmsize', 'Q3_2_leased_area', 'Q3_3_leased_out_area',\n",
    "        'Q3_4_ownership_of_other_farms', 'Q3_5_started_farming',\n",
    "        'Q3_6_ownership_motivation', 'Q3_7_organic', 'Q3_8_local_farming_conditions'\n",
    "    ],\n",
    "    'Section Q4: Crops & Livestock': [\n",
    "        'Q4_1_crop_types', 'Q4_2_crop_reason', 'Q4_3_livestock',\n",
    "        'Q4_4_livestock_type_count', 'Q4_5_livestock_changes_past',\n",
    "        'Q4_6_livestock_changes_future'\n",
    "    ],\n",
    "    'Section Q5: Land Use Changes': [\n",
    "        'Q5_1_arable_to_grass', 'Q5_2_grass_to_arable', 'Q5_3_arable_to_nature',\n",
    "        'Q5_4_nature_to_arable', 'Q5_5_grass_to_nature', 'Q5_6_nature_to_grass',\n",
    "        'Q5_7_other_changes', 'Q5_8_crop_changes_past', 'Q5_9_birds',\n",
    "        'Q5_10_insects', 'Q5_11_other_animals'\n",
    "    ],\n",
    "    'Section Q6: Decision Making': [\n",
    "        'Q6_1_planning_crop_rotation', 'Q6_2_considerations_crops',\n",
    "        'Q6_3_crop_changes_future', 'Q6_4_soil_variation_crops',\n",
    "        'Q6_5_soil_impact_cropchoice', 'Q6_6_terrain_impact_cropchoice',\n",
    "        'Q6_7_drainage_impact_cropchoice', 'Q6_8_changes_fieldplanning',\n",
    "        'Q6_9_good_agricultural_year'\n",
    "    ],\n",
    "    'Section Q7: Legumes': [\n",
    "        'Q7_1_1_Legumes_crop_rotation', 'Q7_1_2_Challenges_legumes',\n",
    "        'Q7_1_3_pros_cons_legumes', 'Q7_1_4_perception_legumes',\n",
    "        'Q7_1_5_Perception_changes_legumes', 'Q7_1_6_advantages_disadvantages_legumes',\n",
    "        'Q7_1_7_barriers_legumes', 'Q7_1_8_benefits_legumes', 'Q7_1_9_cooperation_sales',\n",
    "        'Q7_2_1_experience_legumes', 'Q7_2_2_perception_legumes',\n",
    "        'Q7_2_3_pros_cons_legumes', 'Q7_2_4_advantages_disadvantages_legumes',\n",
    "        'Q7_2_5_expected_challenges_legumes', 'Q7_2_6_incentives_legumes',\n",
    "        'Q7_2_7_benefits_legumes'\n",
    "    ],\n",
    "    'Section Q8: Field Conditions': [\n",
    "        'Q8_1_best_worst_fields', 'Q8_2_drainage_system', 'Q8_3_waterlogged_fields',\n",
    "        'Q8_4_drought_fields', 'Q8_5_plantprotection_fields',\n",
    "        'Q8_6_plantprotection_use_change', 'Q8_7_production_conditions_fields',\n",
    "        'Q8_8_production_security_fields', 'Q8_9_yield_data'\n",
    "    ],\n",
    "    'Section Q9: Society & Admin': [\n",
    "        'Q9_1_farmtype', 'Q9_2_admin_factors_cropchoice', 'Q9_3_env_impact_choice',\n",
    "        'Q9_4_societal_expectations', 'Q9_5_changes_societal_expectations',\n",
    "        'Q9_6_traditions_crops', 'Q9_7_knowlegde_info_sources'\n",
    "    ],\n",
    "    'Section Q10: Landscape': [\n",
    "        'Q10_1_landscape_role', 'Q10_2_landscape_role_changes', 'Q10_3_landscape_steward'\n",
    "    ],\n",
    "    'Section Q11: Future': [\n",
    "        'Q11_1_future_farm_wishes', 'Q11_2_future_legumes', 'Q11_3_biodiversity_considerations',\n",
    "        'Q11_4_climate_adaptation', 'Q11_5_nitrogen_management', 'Q11_6_retrospective_farm',\n",
    "        'Q11_7_Green_tripartite'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8fac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Helper functions\n",
    "def format_ts(seconds: float) -> str:\n",
    "    seconds = int(round(seconds))\n",
    "    h, m = divmod(seconds, 3600)\n",
    "    m, s = divmod(m, 60)\n",
    "    return f\"{h:02}:{m:02}:{s:02}\"\n",
    "\n",
    "def find_audio_file(base_id: str, audio_dir: Path) -> str | None:\n",
    "    \"\"\"Find audio file matching CSV basename.\n",
    "    \n",
    "    Flexible matching: Interview_1 matches interview_1.mp3, interview 1.mp3, etc.\n",
    "    \"\"\"\n",
    "    if not audio_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    # Get all audio files\n",
    "    all_audio = [f for f in audio_dir.glob(\"*\") if f.is_file()]\n",
    "    \n",
    "    # Normalize the base_id: convert to lowercase and extract any numbers\n",
    "    base_lower = base_id.lower()\n",
    "    \n",
    "    # Extract numeric ID if present (e.g., \"interview_1\" -> \"1\")\n",
    "    num_match = re.search(r'\\d+', base_id)\n",
    "    numeric_id = num_match.group(0) if num_match else None\n",
    "    \n",
    "    # Strategy 1: Exact stem match (case-insensitive)\n",
    "    for audio in all_audio:\n",
    "        if audio.stem.lower() == base_lower:\n",
    "            return audio.name\n",
    "    \n",
    "    # Strategy 2: Flexible word + number matching\n",
    "    # Split base into words and numbers, then match flexibly\n",
    "    if numeric_id:\n",
    "        for audio in all_audio:\n",
    "            audio_lower = audio.stem.lower()\n",
    "            # Check if numeric ID is in the audio filename\n",
    "            if numeric_id in audio_lower:\n",
    "                # Also check if common prefixes match\n",
    "                if any(prefix in audio_lower for prefix in ['interview', base_lower.split('_')[0] if '_' in base_lower else '']):\n",
    "                    return audio.name\n",
    "    \n",
    "    # Strategy 3: Simple substring match\n",
    "    for audio in all_audio:\n",
    "        if base_lower in audio.stem.lower():\n",
    "            return audio.name\n",
    "        if audio.stem.lower() in base_lower:\n",
    "            return audio.name\n",
    "    \n",
    "    # Strategy 4: Numeric-only match (if base has a number)\n",
    "    if numeric_id:\n",
    "        for audio in all_audio:\n",
    "            if numeric_id in audio.stem:\n",
    "                return audio.name\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_validation_map(report_path: Path) -> dict:\n",
    "    if not report_path.exists():\n",
    "        return {}\n",
    "    with open(report_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    index = {}\n",
    "    for item in data.get('results', []):\n",
    "        name = Path(item.get('csv_file', '')).name\n",
    "        if name:\n",
    "            index[name] = item\n",
    "    return index\n",
    "\n",
    "def render_validation_block(csv_name: str, report: dict) -> list[str]:\n",
    "    if not report:\n",
    "        return []\n",
    "    flagged = report.get('flagged_count', len(report.get('flagged_segments', [])))\n",
    "    checked = report.get('segments_checked', 0)\n",
    "    lines = []\n",
    "    lines.append('> _VALIDATION_REPORT (delete if not needed)_')\n",
    "    lines.append(f'> File: {csv_name}')\n",
    "    lines.append(f'> Flagged: {flagged}/{checked} segments')\n",
    "    for seg in report.get('flagged_segments', []):\n",
    "        start = seg.get('start', 0)\n",
    "        end = seg.get('end', 0)\n",
    "        speaker = seg.get('speaker', 'Unknown')\n",
    "        issues = seg.get('issues', [])\n",
    "        issues_str = '; '.join([str(i) for i in issues]) if issues else ''\n",
    "        lines.append(f'> - [{format_ts(start)}-{format_ts(end)}] {speaker}: {issues_str}')\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46fdeef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” DETAILED AUDIO FILE MATCHING DEBUG\n",
      "\n",
      "Audio vault: D:\\legendary2\\obsidian_vault\\compact_audio\n",
      "Exists: True\n",
      "\n",
      "Audio files found (88):\n",
      "  â€¢ interview_1.mp3 (stem: interview_1)\n",
      "  â€¢ interview_10.mp3 (stem: interview_10)\n",
      "  â€¢ interview_102.mp3 (stem: interview_102)\n",
      "  â€¢ interview_104.mp3 (stem: interview_104)\n",
      "  â€¢ interview_108.mp3 (stem: interview_108)\n",
      "  â€¢ interview_110.mp3 (stem: interview_110)\n",
      "  â€¢ interview_111.mp3 (stem: interview_111)\n",
      "  â€¢ interview_112.mp3 (stem: interview_112)\n",
      "  â€¢ interview_114.mp3 (stem: interview_114)\n",
      "  â€¢ interview_12.mp3 (stem: interview_12)\n",
      "  â€¢ interview_120.mp3 (stem: interview_120)\n",
      "  â€¢ interview_121.mp3 (stem: interview_121)\n",
      "  â€¢ interview_122.mp3 (stem: interview_122)\n",
      "  â€¢ interview_126.mp3 (stem: interview_126)\n",
      "  â€¢ interview_128.mp3 (stem: interview_128)\n",
      "  â€¢ interview_132.mp3 (stem: interview_132)\n",
      "  â€¢ interview_135.mp3 (stem: interview_135)\n",
      "  â€¢ interview_136.mp3 (stem: interview_136)\n",
      "  â€¢ interview_137.mp3 (stem: interview_137)\n",
      "  â€¢ interview_138.mp3 (stem: interview_138)\n",
      "\n",
      "\n",
      "Testing matching for first 3 CSVs:\n",
      "\n",
      "CSV: Interview_1.csv\n",
      "  Stem: 'Interview_1'\n",
      "  Searching for audio files that match...\n",
      "    âœ… Direct match: interview_1.mp3\n",
      "\n",
      "CSV: Interview_10.csv\n",
      "  Stem: 'Interview_10'\n",
      "  Searching for audio files that match...\n",
      "    âœ… Direct match: interview_10.mp3\n",
      "\n",
      "CSV: Interview_102.csv\n",
      "  Stem: 'Interview_102'\n",
      "  Searching for audio files that match...\n",
      "    âœ… Direct match: interview_102.mp3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Debug: Detailed audio file matching\n",
    "print(\"\\nðŸ” DETAILED AUDIO FILE MATCHING DEBUG\\n\")\n",
    "print(f\"Audio vault: {AUDIO_VAULT_DIR}\")\n",
    "print(f\"Exists: {AUDIO_VAULT_DIR.exists()}\\n\")\n",
    "\n",
    "if AUDIO_VAULT_DIR.exists():\n",
    "    all_audio = sorted([f for f in AUDIO_VAULT_DIR.glob(\"*\") if f.is_file()])\n",
    "    print(f\"Audio files found ({len(all_audio)}):\")\n",
    "    for af in all_audio[:20]:\n",
    "        print(f\"  â€¢ {af.name} (stem: {af.stem})\")\n",
    "    \n",
    "    # Get sample CSVs\n",
    "    csv_files_sample = sorted(TRANSCRIPTS_DIR.glob('*.csv'))[:3]\n",
    "    \n",
    "    print(f\"\\n\\nTesting matching for first {len(csv_files_sample)} CSVs:\\n\")\n",
    "    for csv in csv_files_sample:\n",
    "        base = csv.stem\n",
    "        print(f\"CSV: {csv.name}\")\n",
    "        print(f\"  Stem: '{base}'\")\n",
    "        print(f\"  Searching for audio files that match...\")\n",
    "        \n",
    "        # Try different strategies\n",
    "        found = None\n",
    "        \n",
    "        # Strategy 1: Direct match (case-insensitive)\n",
    "        for audio in all_audio:\n",
    "            if audio.stem.lower() == base.lower():\n",
    "                print(f\"    âœ… Direct match: {audio.name}\")\n",
    "                found = audio.name\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            # Strategy 2: Substring match\n",
    "            for audio in all_audio:\n",
    "                if base.lower() in audio.stem.lower() or audio.stem.lower() in base.lower():\n",
    "                    print(f\"    âœ… Substring match: {audio.name}\")\n",
    "                    found = audio.name\n",
    "                    break\n",
    "        \n",
    "        if not found:\n",
    "            # Show what would match with glob\n",
    "            for pattern in [f\"{base}*\", f\"*{base}*\"]:\n",
    "                matches = list(AUDIO_VAULT_DIR.glob(pattern))\n",
    "                if matches:\n",
    "                    print(f\"    ðŸ“Œ Glob pattern '{pattern}' would match:\")\n",
    "                    for m in matches:\n",
    "                        print(f\"       â†’ {m.name}\")\n",
    "                    found = matches[0].name\n",
    "                    break\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"    âŒ NO MATCH FOUND\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"âŒ Audio vault directory does not exist!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d6216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ EXPORTING 88 TRANSCRIPTS\n",
      "\n",
      "ðŸŽ§ âœ…(7) Interview_1.md\n",
      "ðŸŽ§ âœ…(11) Interview_10.md\n",
      "ðŸŽ§ âœ…(16) Interview_102.md\n",
      "ðŸŽ§    Interview_104.md\n",
      "ðŸŽ§    Interview_108.md\n",
      "ðŸŽ§    Interview_110.md\n",
      "ðŸŽ§    Interview_111.md\n",
      "ðŸŽ§    Interview_112.md\n",
      "ðŸŽ§    Interview_114.md\n",
      "ðŸŽ§    Interview_12.md\n",
      "ðŸŽ§    Interview_120.md\n",
      "ðŸŽ§    Interview_121.md\n",
      "ðŸŽ§    Interview_122.md\n",
      "ðŸŽ§    Interview_126.md\n",
      "ðŸŽ§    Interview_128.md\n",
      "ðŸŽ§    Interview_132.md\n",
      "ðŸŽ§    Interview_135.md\n",
      "ðŸŽ§    Interview_136.md\n",
      "ðŸŽ§    Interview_137.md\n",
      "ðŸŽ§    Interview_138.md\n",
      "ðŸŽ§    Interview_139.md\n",
      "ðŸŽ§    Interview_14.md\n",
      "ðŸŽ§    Interview_140.md\n",
      "ðŸŽ§    Interview_145.md\n",
      "ðŸŽ§    Interview_150.md\n",
      "ðŸŽ§    Interview_151.md\n",
      "ðŸŽ§    Interview_152.md\n",
      "ðŸŽ§    Interview_154.md\n",
      "ðŸŽ§    Interview_156.md\n",
      "ðŸŽ§    Interview_158.md\n",
      "ðŸŽ§    Interview_16.md\n",
      "ðŸŽ§    Interview_160.md\n",
      "ðŸŽ§    Interview_166.md\n",
      "ðŸŽ§    Interview_175.md\n",
      "ðŸŽ§    Interview_177.md\n",
      "ðŸŽ§    Interview_178.md\n",
      "ðŸŽ§    Interview_179.md\n",
      "ðŸŽ§    Interview_180.md\n",
      "ðŸŽ§    Interview_181.md\n",
      "ðŸŽ§    Interview_182.md\n",
      "ðŸŽ§    Interview_183.md\n",
      "ðŸŽ§    Interview_184.md\n",
      "ðŸŽ§    Interview_187.md\n",
      "ðŸŽ§    Interview_194.md\n",
      "ðŸŽ§    Interview_195.md\n",
      "ðŸŽ§    Interview_2.md\n",
      "ðŸŽ§    Interview_20.md\n",
      "ðŸŽ§    Interview_21.md\n",
      "ðŸŽ§    Interview_23.md\n",
      "ðŸŽ§    Interview_3.md\n",
      "ðŸŽ§    Interview_31.md\n",
      "ðŸŽ§    Interview_33.md\n",
      "ðŸŽ§    Interview_34.md\n",
      "ðŸŽ§    Interview_35.md\n",
      "ðŸŽ§    Interview_36.md\n",
      "ðŸŽ§    Interview_37.md\n",
      "ðŸŽ§    Interview_4.md\n",
      "ðŸŽ§    Interview_43.md\n",
      "ðŸŽ§    Interview_44.md\n",
      "ðŸŽ§    Interview_48.md\n",
      "ðŸŽ§    Interview_5.md\n",
      "ðŸŽ§    Interview_50.md\n",
      "ðŸŽ§    Interview_51.md\n",
      "ðŸŽ§    Interview_52.md\n",
      "ðŸŽ§    Interview_55.md\n",
      "ðŸŽ§    Interview_6.md\n",
      "ðŸŽ§    Interview_61.md\n",
      "ðŸŽ§    Interview_62.md\n",
      "ðŸŽ§    Interview_64.md\n",
      "ðŸŽ§    Interview_65.md\n",
      "ðŸŽ§    Interview_66.md\n",
      "ðŸŽ§    Interview_67.md\n",
      "ðŸŽ§    Interview_68.md\n",
      "ðŸŽ§    Interview_7.md\n",
      "ðŸŽ§    Interview_71.md\n",
      "ðŸŽ§    Interview_72.md\n",
      "ðŸŽ§    Interview_74.md\n",
      "ðŸŽ§    Interview_77.md\n",
      "ðŸŽ§    Interview_78.md\n",
      "ðŸŽ§    Interview_8.md\n",
      "ðŸŽ§    Interview_82.md\n",
      "ðŸŽ§    Interview_83.md\n",
      "ðŸŽ§    Interview_86.md\n",
      "ðŸŽ§    Interview_91.md\n",
      "ðŸŽ§    Interview_92.md\n",
      "ðŸŽ§    Interview_94.md\n",
      "ðŸŽ§    Interview_97.md\n",
      "ðŸŽ§    Interview_99.md\n",
      "\n",
      "âœ¨ Exported 88/88 files to D:\\legendary2\\obsidian_vault\n"
     ]
    }
   ],
   "source": [
    "# 5) Export CSV transcripts to Obsidian Markdown\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUDIO_VAULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "validation_map = load_validation_map(VALIDATION_REPORT_PATH)\n",
    "\n",
    "csv_files = sorted(TRANSCRIPTS_DIR.glob('*.csv'))\n",
    "print(f'\\nðŸ“ EXPORTING {len(csv_files)} TRANSCRIPTS\\n')\n",
    "\n",
    "success_count = 0\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    base = csv_path.stem\n",
    "    title = base.replace('_', ' ').title()\n",
    "    out_path = OUTPUT_DIR / f'{base}.md'\n",
    "\n",
    "    # Find audio file\n",
    "    audio_name = find_audio_file(base, AUDIO_VAULT_DIR)\n",
    "    audio_rel_path = f'{compact_audio_subfolder}/{audio_name}' if audio_name else None\n",
    "\n",
    "    # Get validation data for this file\n",
    "    validation_data = validation_map.get(csv_path.name, {})\n",
    "    flagged_segments = {seg['segment_index']: seg for seg in validation_data.get('flagged_segments', [])}\n",
    "\n",
    "    lines = []\n",
    "    # Front matter\n",
    "    lines.append('---')\n",
    "    lines.append(f'title: \"{title}\"')\n",
    "    lines.append(f'date: {datetime.date.today().isoformat()}')\n",
    "    lines.append('tags: [interview]')\n",
    "    lines.append('---\\n')\n",
    "\n",
    "    # Audio embedding\n",
    "    if audio_rel_path:\n",
    "        lines.append('# ðŸŽ§ Recording')\n",
    "        lines.append(f'![[{audio_rel_path}]]\\n')\n",
    "        lines.append('---\\n')\n",
    "    \n",
    "    lines.append('# Transcript\\n')\n",
    "\n",
    "    # Transcript segments with inline validation\n",
    "    for idx, row in df.iterrows():\n",
    "        speaker = str(row.get('Speaker', 'Unknown'))\n",
    "        text = str(row.get('Text', ''))\n",
    "        start = float(row.get('Start', 0))\n",
    "        ts_label = format_ts(start)\n",
    "        ts_int = int(round(start))\n",
    "        \n",
    "        # Build timestamp link\n",
    "        if audio_rel_path:\n",
    "            ts_link = f'[[{audio_rel_path}#t={ts_int}|{ts_label}]]'\n",
    "        else:\n",
    "            ts_link = f'`[{ts_label}]`'\n",
    "        \n",
    "        # Bold target speaker\n",
    "        heading = f'### **{speaker}** {ts_link}' if speaker == TARGET_SPEAKER else f'### {speaker} {ts_link}'\n",
    "        lines.append(heading)\n",
    "        lines.append(text)\n",
    "        \n",
    "        # Add validation block if this segment has issues\n",
    "        if idx in flagged_segments:\n",
    "            val_seg = flagged_segments[idx]\n",
    "            lines.append('')\n",
    "            lines.append('> [!warning]- _Validation Issues (AI-detected, may contain false positives)_')\n",
    "            \n",
    "            # Handle issues - can be list of strings or list of dicts\n",
    "            issues = val_seg.get('issues', [])\n",
    "            if issues:\n",
    "                for issue in issues:\n",
    "                    if isinstance(issue, dict):\n",
    "                        # Issue is a dict with type/description\n",
    "                        issue_text = issue.get('description', str(issue))\n",
    "                    else:\n",
    "                        # Issue is a string\n",
    "                        issue_text = str(issue)\n",
    "                    lines.append(f'> - *#Issue:* _{issue_text}_')\n",
    "            \n",
    "            # Add suggestions\n",
    "            suggestions = val_seg.get('suggestions')\n",
    "            if suggestions:\n",
    "                lines.append(f'> - *#Suggestions:* _{suggestions}_')\n",
    "            \n",
    "            # Add confidence\n",
    "            confidence = val_seg.get('confidence')\n",
    "            if confidence:\n",
    "                lines.append(f'> - *Confidence:* {confidence:.0%}')\n",
    "        \n",
    "        lines.append('')\n",
    "\n",
    "    # Questionnaire section\n",
    "    lines.append('---')\n",
    "    lines.append('# ðŸ“Š Interview Data')\n",
    "    lines.append('> [!INFO]- Questionnaire')\n",
    "    lines.append('> Click to expand and fill in answers.')\n",
    "    lines.append('>')\n",
    "    for section, questions in QUESTION_SECTIONS.items():\n",
    "        lines.append(f'> %% {section} %%')\n",
    "        for q in questions:\n",
    "            lines.append(f'> **{q}**:: ')\n",
    "        lines.append('>')\n",
    "\n",
    "    # Write file\n",
    "    out_path.write_text('\\n'.join(lines), encoding='utf-8')\n",
    "    \n",
    "    audio_status = 'ðŸŽ§' if audio_rel_path else 'âš ï¸ '\n",
    "    val_count = len(flagged_segments)\n",
    "    val_status = f'âœ…({val_count})' if val_count > 0 else '  '\n",
    "    print(f'{audio_status} {val_status} {out_path.name}')\n",
    "    success_count += 1\n",
    "\n",
    "print(f'\\nâœ¨ Exported {success_count}/{len(csv_files)} files to {OUTPUT_DIR}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qualivault",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
